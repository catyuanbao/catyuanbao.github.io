<!DOCTYPE html>
<html lang="zh-Hans">

<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta name="x5-fullscreen" content="true">
<meta name="full-screen" content="yes">
<meta name="theme-color" content="#317EFB" />
<meta content="width=device-width, initial-scale=1.0, maximum-scale=5.0, user-scalable=0" name="viewport">
<meta name="description" content="本文主要记录Fast Python第三章，主要是介绍Python异步编程，实现一个简单的MapReduce服务端。 并发并行和顺序执行Parallelism is the easiest concept to explain: tasks run in parallel when they are run- ning at the same time. Concurrent tasks may r">
<meta property="og:type" content="article">
<meta property="og:title" content="Fast Python笔记二">
<meta property="og:url" content="http://example.com/2024/05/26/Fast-Python%E7%AC%94%E8%AE%B0%E4%BA%8C/index.html">
<meta property="og:site_name" content="Cat YuanBao">
<meta property="og:description" content="本文主要记录Fast Python第三章，主要是介绍Python异步编程，实现一个简单的MapReduce服务端。 并发并行和顺序执行Parallelism is the easiest concept to explain: tasks run in parallel when they are run- ning at the same time. Concurrent tasks may r">
<meta property="og:locale">
<meta property="article:published_time" content="2024-05-26T04:06:42.000Z">
<meta property="article:modified_time" content="2024-05-26T04:25:17.302Z">
<meta property="article:author" content="橘猫元宝">
<meta property="article:tag" content="cat">
<meta name="twitter:card" content="summary">

    <meta name="keywords" content="cat">


<title >Fast Python笔记二</title>

<!-- Favicon -->

    <link href='/img/favicon.svg?v=2.1.8' rel='icon' type='image/png' sizes='16x16' ></link>


    <link href='/img/favicon.svg?v=2.1.8' rel='icon' type='image/png' sizes='32x32' ></link>




<!-- Plugin -->




    
<link rel="stylesheet" href="/css/plugins/bootstrap.row.css">

    
<link rel="stylesheet" href="https://unpkg.com/@fancyapps/ui@4.0/dist/fancybox.css">

    
    




<!-- Icon -->

    
<link rel="stylesheet" href="/css/plugins/font-awesome.min.css">




<!-- Variable -->
<script>window.ASYNC_CONFIG = {"hostname":"example.com","author":"橘猫元宝","root":"/","typed_text":null,"theme_version":"2.1.8","theme":{"switch":true,"default":"style-light"},"favicon":{"logo":"/img/favicon.svg","icon16":"/img/favicon.svg","icon32":"/img/favicon.svg","appleTouchIcon":null,"webmanifest":null,"visibilitychange":false,"hidden":"/failure.ico","showText":"(/≧▽≦/)咦！又好了！","hideText":"(●—●)喔哟，崩溃啦！"},"i18n":{"placeholder":"搜索文章...","empty":"找不到您查询的内容: ${query}","hits":"找到 ${hits} 条结果","hits_time":"找到 ${hits} 条结果（用时 ${time} 毫秒）","author":"本文作者：","copyright_link":"本文链接：","copyright_license_title":"版权声明：","copyright_license_content":"本博客所有文章除特别声明外，均默认采用 undefined 许可协议。","copy_success":"复制成功","copy_failure":"复制失败","open_read_mode":"进入阅读模式","exit_read_mode":"退出阅读模式","notice_outdate_message":"距离上次更新已经 undefined 天了, 文章内容可能已经过时。","sticky":"置顶","just":"刚刚","min":"分钟前","hour":"小时前","day":"天前","month":"个月前"},"swup":false,"plugin":{"flickr_justified_gallery":"https://unpkg.com/flickr-justified-gallery@latest/dist/fjGallery.min.js"},"icons":{"sun":"far fa-sun","moon":"far fa-moon","play":"fas fa-play","email":"far fa-envelope","next":"fas fa-arrow-right","calendar":"far fa-calendar-alt","clock":"far fa-clock","user":"far fa-user","back_top":"fas fa-arrow-up","close":"fas fa-times","search":"fas fa-search","reward":"fas fa-hand-holding-usd","user_tag":"fas fa-user-alt","toc_tag":"fas fa-th-list","read":"fas fa-book-reader","arrows":"fas fa-arrows-alt-h","double_arrows":"fas fa-angle-double-down","copy":"fas fa-copy"},"icontype":"font","highlight":{"plugin":"prismjs","theme":true,"copy":true,"lang":true,"title":"default","height_limit":false},"toc":{"post_title":true}};</script>
<script id="async-page-config">window.PAGE_CONFIG = {"isPost":true,"isHome":false,"postUpdate":"2024-05-26 12:25:17"};</script>

<!-- Theme mode css -->
<link data-swup-theme rel="stylesheet" href="/css/index.css?v=2.1.8" id="trm-switch-style">
<script>
    let defaultMode = ASYNC_CONFIG.theme.default !=='auto' ?  ASYNC_CONFIG.theme.default : (window.matchMedia("(prefers-color-scheme: light)").matches ? 'style-light' : 'style-dark')
    let catchMode = localStorage.getItem('theme-mode') || defaultMode;
    let type = catchMode === 'style-dark' ? 'add' : 'remove';
    document.documentElement.classList[type]('dark')
</script>

<!-- CDN -->


    
    



<!-- Site Analytics -->
 
<meta name="generator" content="Hexo 7.0.0"><link rel="stylesheet" href="/css/prism.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head>

<body>

  <!-- app wrapper -->
  <div class="trm-app-frame">

    <!-- page preloader -->
    <div class="trm-preloader">
    <div class="trm-holder">
        <div class="preloader">
            <div></div>
            <div></div>
            <div></div>
            <div></div>
            <div></div>
            <div></div>
            <div></div>
            <div></div>
            <div></div>
            <div></div>
        </div>
    </div>
</div>
    <!-- page preloader end -->

    <!-- change mode preloader -->
    <div class="trm-mode-swich-animation-frame">
    <div class="trm-mode-swich-animation">
        <i class="i-sun"><i class="iconfont far fa-sun"></i></i>
        <div class="trm-horizon"></div>
        <i class="i-moon"><i class="iconfont far fa-moon"></i></i>
    </div>
</div>
    <!-- change mode preloader end -->

      <!-- scroll container -->
      <div id="trm-dynamic-content" class="trm-swup-animation">
        <div id="trm-scroll-container" class="trm-scroll-container" style="opacity: 0">
            <!-- top bar -->
            <header class="trm-top-bar">
	<div class="container">
		<div class="trm-left-side">
			<!-- logo -->
<a href="/" class="trm-logo-frame trm-anima-link">
    
        <img alt="logo" src="/img/favicon.svg">
    
    
        <div class="trm-logo-text">
            元宝<span>橘猫</span>
        </div>
    
</a>
<!-- logo end -->
		</div>
		<div class="trm-right-side">
			<!-- menu -->
<div class="trm-menu">
    <nav>
        <ul>
            
            <li class="menu-item-has-children ">
                <a  href="/" target="">
                    首页
                </a>
                
            </li>
            
            <li class="menu-item-has-children ">
                <a  href="/archives/" target="">
                    归档
                </a>
                
            </li>
            
        </ul>
    </nav>
</div>
<!-- menu end -->
			
    <!-- mode switcher place -->
    <div class="trm-mode-switcher-place">
        <div class="trm-mode-switcher">
            <i class="iconfont far fa-sun"></i>
            <input class="tgl tgl-light" id="trm-swich" type="checkbox">
            <label class="trm-swich" for="trm-swich"></label>
            <i class="iconfont far fa-moon"></i>
        </div>
    </div>
    <!-- mode switcher place end -->

			
		</div>
		<div class="trm-menu-btn">
			<span></span>
		</div>
	</div>
</header>
            <!-- top bar end -->

            <!-- body -->
            
<div class="trm-content-start">
    <!-- banner -->
    <div class="trm-banner">
    
    <!-- banner cover -->
    <img style="object-position:top;object-fit:cover;" alt="banner" class="trm-banner-cover" src="/img/banner.png">
    <!-- banner cover end -->
    

    <!-- banner content -->
    <div class="trm-banner-content trm-overlay">
        <div class="container">
            <div class="row">
                
                <div class="col-lg-4"></div>
                
                <div class="col-lg-8">

                    <!-- banner title -->
                    <div class="trm-banner-text ">
                        <div class="trm-label trm-mb-20">
                            NEWS LETTER
                        </div>
                        <h1 class="trm-mb-30 trm-hsmb-font">
                            Fast Python笔记二
                        </h1>

                        
                            <ul class="trm-breadcrumbs trm-label">
                                <li>
                                    <a href="/" class="trm-anima-link">Home</a>
                                </li>
                                <li>
                                    <span>
                                        2024
                                    </span>
                                </li>
                            </ul>
                        
                    </div>
                    <!-- banner title end -->

                    <!-- scroll hint -->
                    <span id="scroll-triger" class="trm-scroll-hint-frame">
                        <div class="trm-scroll-hint"></div>
                        <span class="trm-label">Scroll down</span>
                    </span>
                    <!-- scroll hint end -->

                </div>
            </div>
        </div>
    </div>
    <!-- banner content end -->
</div>
    <!-- banner end -->
    <div class="container">
        <div class="row">
            
                <div class="trm-page-sidebar col-lg-4 hidden-sm">
                    <!-- main card -->
                    <div class="trm-main-card-frame trm-sidebar">
    <div class="trm-main-card"> 
        <!-- card header -->
<div class="trm-mc-header">
    <div class="trm-avatar-frame trm-mb-20">
        <img alt="Avatar" class="trm-avatar" src="/img/cat.jpg">
    </div>
    <h5 class="trm-name trm-mb-15">
        橘猫元宝
    </h5>
    
</div>
<!-- card header end -->
        <!-- sidebar social -->

<div class="trm-divider trm-mb-40 trm-mt-40"></div>
<div class="trm-social">
    
        <a href="https://github.com" title="Github" rel="nofollow" target="_blank">
            <i class="iconfont fab fa-github"></i>
        </a>
    
</div>

<!-- sidebar social end -->
        <!-- info -->
<div class="trm-divider trm-mb-40 trm-mt-40"></div>
<ul class="trm-table trm-mb-20">
    
        <li>
            <div class="trm-label">
                Residence:
            </div>
            <div class="trm-label trm-label-light">
                Mars
            </div>
        </li>
    
</ul>
<!-- info end -->

        
    </div>
</div>
                    <!-- main card end -->
                </div>
            
            <div class="trm-page-content col-lg-8">
                <div id="trm-content" class="trm-content">
                    <div class="trm-post-info row hidden-sm">
    <div class="col-sm-4">
        <div class="trm-card trm-label trm-label-light text-center">
            <i class="iconfont far fa-calendar-alt trm-icon"></i><br>
            05/26
        </div>
    </div>
    <div class="col-sm-4">
        <div class="trm-card trm-label trm-label-light text-center">
            <i class="iconfont far fa-clock trm-icon"></i><br>
            12:06
        </div>
    </div>
    <div class="col-sm-4">
        <div id="post-author" class="trm-card trm-label trm-label-light text-center">
            <i class="iconfont far fa-user trm-icon"></i><br>
            橘猫元宝
        </div>
    </div>
</div>
<div class="trm-card ">
    <article id="article-container" class="trm-publication">
    <p>本文主要记录Fast Python第三章，主要是介绍Python异步编程，实现一个简单的MapReduce服务端。</p>
<h3 id="并发并行和顺序执行"><a href="#并发并行和顺序执行" class="headerlink" title="并发并行和顺序执行"></a>并发并行和顺序执行</h3><pre class="line-numbers language-bash"><code class="language-bash">Parallelism is the easiest concept to explain: tasks run <span class="token keyword">in</span> parallel when they are run-
ning at the same time. Concurrent tasks may run <span class="token keyword">in</span> any order: they may be run <span class="token keyword">in</span>
parallel or <span class="token keyword">in</span> sequence, depending on the language and OS. So all parallel tasks are
concurrent but not the other way around.

Understanding sequential, concurrent, and parallel models. Sequential execution occurs
when all tasks are executed <span class="token keyword">in</span> sequence and never interrupted. Concurrent execution with
no parallelism adds the possibility of a task being interrupted by another and later resumed.
Parallelism occurs when several tasks are run at the same time.
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>Parallelism是多个任务同时执行（强调同时），Concurrent是多个任务以任意顺序执行（强调多个任务执行）。</p>
<h3 id="单进程协程服务器实例"><a href="#单进程协程服务器实例" class="headerlink" title="单进程协程服务器实例"></a>单进程协程服务器实例</h3><p>这里给出一个MapReduce的单进程+协程的服务器实例。</p>
<p>客户端可以提交任务，并获取执行结果，这里第一个版本只有简单的返回一个随机数，并没有计算word的次数 基于Python asyncio模块实现：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> asyncio
<span class="token keyword">import</span> pickle
<span class="token keyword">from</span> random <span class="token keyword">import</span> randint

results <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>


<span class="token keyword">async</span> <span class="token keyword">def</span> <span class="token function">submit_job</span><span class="token punctuation">(</span>reader<span class="token punctuation">,</span> writer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    job_id <span class="token operator">=</span> max<span class="token punctuation">(</span>list<span class="token punctuation">(</span>results<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span>
    writer<span class="token punctuation">.</span>write<span class="token punctuation">(</span>job_id<span class="token punctuation">.</span>to_bytes<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token string">'little'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
    sleep_time <span class="token operator">=</span> randint<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
    <span class="token keyword">await</span> asyncio<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span>sleep_time<span class="token punctuation">)</span>
    results<span class="token punctuation">[</span>job_id<span class="token punctuation">]</span> <span class="token operator">=</span> sleep_time


<span class="token keyword">async</span> <span class="token keyword">def</span> <span class="token function">get_results</span><span class="token punctuation">(</span>reader<span class="token punctuation">,</span> writer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    job_id <span class="token operator">=</span> int<span class="token punctuation">.</span>from_bytes<span class="token punctuation">(</span><span class="token keyword">await</span> reader<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'little'</span><span class="token punctuation">)</span>
    data <span class="token operator">=</span> pickle<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>results<span class="token punctuation">.</span>get<span class="token punctuation">(</span>job_id<span class="token punctuation">,</span> None<span class="token punctuation">)</span><span class="token punctuation">)</span>
    writer<span class="token punctuation">.</span>write<span class="token punctuation">(</span>len<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">.</span>to_bytes<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token string">'little'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    writer<span class="token punctuation">.</span>write<span class="token punctuation">(</span>data<span class="token punctuation">)</span>


<span class="token keyword">async</span> <span class="token keyword">def</span> <span class="token function">accept_requests</span><span class="token punctuation">(</span>reader<span class="token punctuation">,</span> writer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    op <span class="token operator">=</span> <span class="token keyword">await</span> reader<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> op<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        <span class="token keyword">await</span> submit_job<span class="token punctuation">(</span>reader<span class="token punctuation">,</span> writer<span class="token punctuation">)</span>
    <span class="token keyword">elif</span> op<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
        <span class="token keyword">await</span> get_results<span class="token punctuation">(</span>reader<span class="token punctuation">,</span> writer<span class="token punctuation">)</span>


<span class="token keyword">async</span> <span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    server <span class="token operator">=</span> <span class="token keyword">await</span> asyncio<span class="token punctuation">.</span>start_server<span class="token punctuation">(</span>accept_requests<span class="token punctuation">,</span> <span class="token string">'127.0.0.1'</span><span class="token punctuation">,</span> <span class="token number">1936</span><span class="token punctuation">)</span>
    <span class="token keyword">async</span> <span class="token keyword">with</span> server<span class="token punctuation">:</span>
        <span class="token keyword">await</span> server<span class="token punctuation">.</span>serve_forever<span class="token punctuation">(</span><span class="token punctuation">)</span>


<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'listen at 172.0.0.1 1936 port'</span><span class="token punctuation">)</span>
asyncio<span class="token punctuation">.</span>run<span class="token punctuation">(</span>main<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>客户端实现：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> marshal
<span class="token keyword">import</span> pickle
<span class="token keyword">import</span> socket
<span class="token keyword">from</span> time <span class="token keyword">import</span> sleep


<span class="token keyword">def</span> <span class="token function">my_funs</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">mapper</span><span class="token punctuation">(</span>v<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> v<span class="token punctuation">,</span> <span class="token number">1</span>  <span class="token comment" spellcheck="true"># XXX</span>

    <span class="token keyword">def</span> <span class="token function">reducer</span><span class="token punctuation">(</span>my_args<span class="token punctuation">)</span><span class="token punctuation">:</span>
        v<span class="token punctuation">,</span> obs <span class="token operator">=</span> my_args
        <span class="token keyword">return</span> v<span class="token punctuation">,</span> sum<span class="token punctuation">(</span>obs<span class="token punctuation">)</span>
    <span class="token keyword">return</span> mapper<span class="token punctuation">,</span> reducer


<span class="token keyword">def</span> <span class="token function">do_request</span><span class="token punctuation">(</span>my_funs<span class="token punctuation">,</span> data<span class="token punctuation">)</span><span class="token punctuation">:</span>
    conn <span class="token operator">=</span> socket<span class="token punctuation">.</span>create_connection<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">'127.0.0.1'</span><span class="token punctuation">,</span> <span class="token number">1936</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    conn<span class="token punctuation">.</span>send<span class="token punctuation">(</span>b<span class="token string">'\x00'</span><span class="token punctuation">)</span>
    my_code <span class="token operator">=</span> marshal<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>my_funs<span class="token punctuation">.</span>__code__<span class="token punctuation">)</span>
    conn<span class="token punctuation">.</span>send<span class="token punctuation">(</span>len<span class="token punctuation">(</span>my_code<span class="token punctuation">)</span><span class="token punctuation">.</span>to_bytes<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token string">'little'</span><span class="token punctuation">,</span> signed<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    conn<span class="token punctuation">.</span>send<span class="token punctuation">(</span>my_code<span class="token punctuation">)</span>
    my_data <span class="token operator">=</span> pickle<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
    conn<span class="token punctuation">.</span>send<span class="token punctuation">(</span>len<span class="token punctuation">(</span>my_data<span class="token punctuation">)</span><span class="token punctuation">.</span>to_bytes<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token string">'little'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    conn<span class="token punctuation">.</span>send<span class="token punctuation">(</span>my_data<span class="token punctuation">)</span>
    job_id <span class="token operator">=</span> int<span class="token punctuation">.</span>from_bytes<span class="token punctuation">(</span>conn<span class="token punctuation">.</span>recv<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'little'</span><span class="token punctuation">)</span>
    conn<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'Getting data from job_id {job_id}'</span><span class="token punctuation">)</span>
    result <span class="token operator">=</span> None
    <span class="token keyword">while</span> result <span class="token keyword">is</span> None<span class="token punctuation">:</span>
        conn <span class="token operator">=</span> socket<span class="token punctuation">.</span>create_connection<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">'127.0.0.1'</span><span class="token punctuation">,</span> <span class="token number">1936</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        conn<span class="token punctuation">.</span>send<span class="token punctuation">(</span>b<span class="token string">'\x01'</span><span class="token punctuation">)</span>
        conn<span class="token punctuation">.</span>send<span class="token punctuation">(</span>job_id<span class="token punctuation">.</span>to_bytes<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token string">'little'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        result_size <span class="token operator">=</span> int<span class="token punctuation">.</span>from_bytes<span class="token punctuation">(</span>conn<span class="token punctuation">.</span>recv<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'little'</span><span class="token punctuation">)</span>
        result <span class="token operator">=</span> pickle<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>conn<span class="token punctuation">.</span>recv<span class="token punctuation">(</span>result_size<span class="token punctuation">)</span><span class="token punctuation">)</span>
        conn<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
        sleep<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'Result is {result} Number 1-4'</span><span class="token punctuation">)</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    do_request<span class="token punctuation">(</span>my_funs<span class="token punctuation">,</span> <span class="token string">'Python rocks. Python is great'</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>多运行几次的运行结果：</p>
<pre class="line-numbers language-bash"><code class="language-bash">$ python3 map_c.py
Getting data from job_id 8
Result is 1 Number 1-4
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>仅仅返回一个随机数。</p>
<p>实现MapReduce的基本算法：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> collections <span class="token keyword">import</span> defaultdict


<span class="token keyword">def</span> <span class="token function">map_reduce_ultra_naive</span><span class="token punctuation">(</span>my_input<span class="token punctuation">,</span> mapper<span class="token punctuation">,</span> reducer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    map_results <span class="token operator">=</span> map<span class="token punctuation">(</span>mapper<span class="token punctuation">,</span> my_input<span class="token punctuation">)</span>

    distributor <span class="token operator">=</span> defaultdict<span class="token punctuation">(</span>list<span class="token punctuation">)</span>
    <span class="token keyword">for</span> key<span class="token punctuation">,</span> value <span class="token keyword">in</span> map_results<span class="token punctuation">:</span>
        distributor<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>value<span class="token punctuation">)</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span>distributor<span class="token punctuation">)</span>
    <span class="token keyword">return</span> map<span class="token punctuation">(</span>reducer<span class="token punctuation">,</span> distributor<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>


words <span class="token operator">=</span> <span class="token string">'Python is great Python rocks'</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span>

emiter <span class="token operator">=</span> <span class="token keyword">lambda</span> word<span class="token punctuation">:</span> <span class="token punctuation">(</span>word<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
counter <span class="token operator">=</span> <span class="token keyword">lambda</span> emitted<span class="token punctuation">:</span> <span class="token punctuation">(</span>emitted<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> sum<span class="token punctuation">(</span>emitted<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

a <span class="token operator">=</span> list<span class="token punctuation">(</span>map_reduce_ultra_naive<span class="token punctuation">(</span>words<span class="token punctuation">,</span> emiter<span class="token punctuation">,</span> counter<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>使用 concurrent.futures 实现一个线程版本的mapreduse:</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> collections <span class="token keyword">import</span> defaultdict
<span class="token keyword">from</span> concurrent<span class="token punctuation">.</span>futures <span class="token keyword">import</span> ThreadPoolExecutor <span class="token keyword">as</span> Executor


<span class="token keyword">def</span> <span class="token function">map_reduce_still_naive</span><span class="token punctuation">(</span>my_input<span class="token punctuation">,</span> mapper<span class="token punctuation">,</span> reducer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">with</span> Executor<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> executor<span class="token punctuation">:</span>
        map_results <span class="token operator">=</span> executor<span class="token punctuation">.</span>map<span class="token punctuation">(</span>mapper<span class="token punctuation">,</span> my_input<span class="token punctuation">)</span>
        distributor <span class="token operator">=</span> defaultdict<span class="token punctuation">(</span>list<span class="token punctuation">)</span>
        <span class="token keyword">for</span> key<span class="token punctuation">,</span> value <span class="token keyword">in</span> map_results<span class="token punctuation">:</span>
            distributor<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>value<span class="token punctuation">)</span>
        results <span class="token operator">=</span> executor<span class="token punctuation">.</span>map<span class="token punctuation">(</span>reducer<span class="token punctuation">,</span> distributor<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> results


words <span class="token operator">=</span> filter<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token operator">!=</span> <span class="token string">''</span><span class="token punctuation">,</span> map<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>rstrip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>open<span class="token punctuation">(</span><span class="token string">'text.txt'</span><span class="token punctuation">,</span> <span class="token string">'rt'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

emiter <span class="token operator">=</span> <span class="token keyword">lambda</span> word<span class="token punctuation">:</span> <span class="token punctuation">(</span>word<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
counter <span class="token operator">=</span> <span class="token keyword">lambda</span> emitted<span class="token punctuation">:</span> <span class="token punctuation">(</span>emitted<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> sum<span class="token punctuation">(</span>emitted<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

a <span class="token operator">=</span> list<span class="token punctuation">(</span>map_reduce_still_naive<span class="token punctuation">(</span>words<span class="token punctuation">,</span> emiter<span class="token punctuation">,</span> counter<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> i <span class="token keyword">in</span> sorted<span class="token punctuation">(</span>a<span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这段代码使用了 ThreadPoolExecutor 类来实现并发的 MapReduce 框架。ThreadPoolExecutor 可以创建一个线程池，可以让你并发地执行多个任务。</p>
<p>线程池中的线程个数取自 os.cpu_count() 一般为系统的逻辑核心数。</p>
<p>实现一个带有任务进度显示的mapreduce版本：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> collections <span class="token keyword">import</span> defaultdict
<span class="token keyword">from</span> concurrent<span class="token punctuation">.</span>futures <span class="token keyword">import</span> ThreadPoolExecutor <span class="token keyword">as</span> Executor
<span class="token keyword">from</span> time <span class="token keyword">import</span> sleep


<span class="token keyword">def</span> <span class="token function">report_progress</span><span class="token punctuation">(</span>futures<span class="token punctuation">,</span> tag<span class="token punctuation">,</span> callback<span class="token punctuation">)</span><span class="token punctuation">:</span>
    not_done <span class="token operator">=</span> <span class="token number">1</span>
    done <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">while</span> not_done <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span>
        not_done <span class="token operator">=</span> <span class="token number">0</span>
        done <span class="token operator">=</span> <span class="token number">0</span>
        <span class="token keyword">for</span> fut <span class="token keyword">in</span> futures<span class="token punctuation">:</span>
            <span class="token keyword">if</span> fut<span class="token punctuation">.</span>done<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                done <span class="token operator">+=</span><span class="token number">1</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                not_done <span class="token operator">+=</span> <span class="token number">1</span>
        sleep<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> not_done <span class="token operator">></span> <span class="token number">0</span> <span class="token operator">and</span> callback<span class="token punctuation">:</span>
            callback<span class="token punctuation">(</span>tag<span class="token punctuation">,</span> done<span class="token punctuation">,</span> not_done<span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">async_map</span><span class="token punctuation">(</span>executor<span class="token punctuation">,</span> mapper<span class="token punctuation">,</span> data<span class="token punctuation">)</span><span class="token punctuation">:</span>
    futures <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> datum <span class="token keyword">in</span> data<span class="token punctuation">:</span>
        futures<span class="token punctuation">.</span>append<span class="token punctuation">(</span>executor<span class="token punctuation">.</span>submit<span class="token punctuation">(</span>mapper<span class="token punctuation">,</span> datum<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> futures


<span class="token keyword">def</span> <span class="token function">map_less_naive</span><span class="token punctuation">(</span>executor<span class="token punctuation">,</span> my_input<span class="token punctuation">,</span> mapper<span class="token punctuation">)</span><span class="token punctuation">:</span>
    map_results <span class="token operator">=</span> async_map<span class="token punctuation">(</span>executor<span class="token punctuation">,</span> mapper<span class="token punctuation">,</span> my_input<span class="token punctuation">)</span>
    <span class="token keyword">return</span> map_results


<span class="token keyword">def</span> <span class="token function">map_reduce_less_naive</span><span class="token punctuation">(</span>my_input<span class="token punctuation">,</span> mapper<span class="token punctuation">,</span> reducer<span class="token punctuation">,</span> callback<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">with</span> Executor<span class="token punctuation">(</span>max_workers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token keyword">as</span> executor<span class="token punctuation">:</span>
        futures <span class="token operator">=</span> async_map<span class="token punctuation">(</span>executor<span class="token punctuation">,</span> mapper<span class="token punctuation">,</span> my_input<span class="token punctuation">)</span>
        report_progress<span class="token punctuation">(</span>futures<span class="token punctuation">,</span> <span class="token string">'map'</span><span class="token punctuation">,</span> callback<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true">#wait(futures).done</span>
        map_results <span class="token operator">=</span> map<span class="token punctuation">(</span><span class="token keyword">lambda</span> f<span class="token punctuation">:</span> f<span class="token punctuation">.</span>result<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> futures<span class="token punctuation">)</span>
        distributor <span class="token operator">=</span> defaultdict<span class="token punctuation">(</span>list<span class="token punctuation">)</span>
        <span class="token keyword">for</span> key<span class="token punctuation">,</span> value <span class="token keyword">in</span> map_results<span class="token punctuation">:</span>
            distributor<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>value<span class="token punctuation">)</span>

        futures <span class="token operator">=</span> async_map<span class="token punctuation">(</span>executor<span class="token punctuation">,</span> reducer<span class="token punctuation">,</span> distributor<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        report_progress<span class="token punctuation">(</span>futures<span class="token punctuation">,</span> <span class="token string">'reduce'</span><span class="token punctuation">,</span> callback<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true">#wait(futures).done</span>
        results <span class="token operator">=</span> map<span class="token punctuation">(</span><span class="token keyword">lambda</span> f<span class="token punctuation">:</span> f<span class="token punctuation">.</span>result<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> futures<span class="token punctuation">)</span>
    <span class="token keyword">return</span> results


<span class="token keyword">def</span> <span class="token function">emitter</span><span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true">#sleep(10)</span>
    <span class="token keyword">return</span> word<span class="token punctuation">,</span> <span class="token number">1</span>


counter <span class="token operator">=</span> <span class="token keyword">lambda</span> emitted<span class="token punctuation">:</span> <span class="token punctuation">(</span>emitted<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> sum<span class="token punctuation">(</span>emitted<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">reporter</span><span class="token punctuation">(</span>tag<span class="token punctuation">,</span> done<span class="token punctuation">,</span> not_done<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'Operation {tag}: {done}/{done+not_done}'</span><span class="token punctuation">)</span>

words <span class="token operator">=</span> <span class="token string">'Python is great Python rocks'</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span>
a <span class="token operator">=</span> map_reduce_less_naive<span class="token punctuation">(</span>words<span class="token punctuation">,</span> emitter<span class="token punctuation">,</span> counter<span class="token punctuation">,</span> reporter<span class="token punctuation">)</span>

<span class="token keyword">for</span> i <span class="token keyword">in</span> sorted<span class="token punctuation">(</span>a<span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#words = 'Python is great Python rocks'.split(' ')</span>

<span class="token comment" spellcheck="true">#with Executor(max_workers=4) as executor:</span>
<span class="token comment" spellcheck="true">#    maps = map_less_naive(executor, words, emitter)</span>
<span class="token comment" spellcheck="true">#    print(maps[-1])</span>
<span class="token comment" spellcheck="true">#    not_done = 1</span>
<span class="token comment" spellcheck="true">#    while not_done > 0:</span>
<span class="token comment" spellcheck="true">#        not_done = 0</span>
<span class="token comment" spellcheck="true">#        for fut in maps:</span>
<span class="token comment" spellcheck="true">#            not_done += 1 if not fut.done() else 0</span>
<span class="token comment" spellcheck="true">#        sleep(1)</span>
<span class="token comment" spellcheck="true">#        print(f'Still not finalized: {not_done}')</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>运行结果：</p>
<pre class="line-numbers language-bash"><code class="language-bash">Operation map: 3/5
Operation reduce: 0/4
<span class="token punctuation">(</span><span class="token string">'is'</span>, 1<span class="token punctuation">)</span>
<span class="token punctuation">(</span><span class="token string">'great'</span>, 1<span class="token punctuation">)</span>
<span class="token punctuation">(</span><span class="token string">'rocks'</span>, 1<span class="token punctuation">)</span>
<span class="token punctuation">(</span><span class="token string">'Python'</span>, 2<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>CPython 中的全局解释器锁（GIL）阻止了多个本地线程同时执行 Python 字节码，这确实限制了 CPU 密集型任务的真正并行性。因此，尽管提供的解决方案利用了线程的并发性，但由于 GIL 的限制，它并不能实现真正的并行性。</p>
<p>要在 Python 中实现并行计算，特别是对于像这个 MapReduce 实现这样的 CPU 密集型任务，你通常会考虑使用多进程而不是多线程。多进程允许 Python 通过创建单独的进程来绕过 GIL，每个进程都有自己的 Python 解释器和内存空间。</p>
<p>在 MapReduce 的背景下，你可以用 <code>concurrent.futures</code> 模块中的 <code>ProcessPoolExecutor</code> 替换 <code>ThreadPoolExecutor</code> 来实现真正的并行性。这将涉及启动多个 Python 进程，以便在 CPU 核心之间并行地执行映射和归约任务，从而更好地利用可用的硬件资源。</p>
<p>虽然 CPython 中的全局解释器锁（GIL）会限制 Python  字节码级别的并行执行，但是低级别的代码可以通过一些方式绕过这一限制。在进入低级别的解决方案时，你可以释放  GIL，并使用并行性来充分利用系统资源。这就是诸如 NumPy、SciPy 和 scikit-learn 这样的库所做的。它们在 C 或  Fortran 中编写了多线程代码，释放了 GIL，并且实际上是并行的。因此，在 Python  的线程环境中，你的代码仍然可以实现并行性。只是并行的部分不会用 Python 编写。</p>
<h3 id="关于PyPy和Jython"><a href="#关于PyPy和Jython" class="headerlink" title="关于PyPy和Jython"></a>关于PyPy和Jython</h3><p>PyPy 是另一个流行的 Python 解释器，与 CPython 不同，PyPy 有一个可选的 GIL。在默认情况下，PyPy 也会使用 GIL 来确保线程安全。但是，PyPy 具有一些可配置选项，允许在特定情况下禁用 GIL，以便在某些多线程场景中获得更好的性能。</p>
<p>要注意的是，尽管 PyPy 允许禁用 GIL，但并不意味着它完全消除了多线程中的竞争条件或死锁等问题。因此，在使用 PyPy 进行多线程编程时，仍然需要谨慎处理共享资源并避免潜在的并发问题。</p>
<p>Jython 是另一种 Python 解释器，它将 Python 代码转换为 Java 字节码，以在 Java 虚拟机 (JVM) 上运行。尽管 Jython 提供了与 Java 互操作性的优势，但是自2017年以来，Jython 的更新速度相对缓慢，并且目前处于较低的活跃状态。</p>
<h3 id="多进程版本实现并行"><a href="#多进程版本实现并行" class="headerlink" title="多进程版本实现并行"></a>多进程版本实现并行</h3><p>由于GIL的存在，目前的版本并没有实现并行，无非利用多核心的优势，所以，需要使用多进程的方式，充分利用多核计算能力。</p>
<h4 id="pickle-多进程的问题"><a href="#pickle-多进程的问题" class="headerlink" title="pickle 多进程的问题"></a>pickle 多进程的问题</h4><p>在 Python 中，pickle 是一种用于序列化和反序列化 Python 对象的标准模块。然而，pickle 在多进程环境下存在一些限制，特别是在使用 multiprocessing 模块创建子进程时。</p>
<p>具体来说，当使用 multiprocessing 模块创建的子进程尝试序列化或反序列化对象时，由于子进程无法直接访问父进程的内存空间，因此 pickle 会遇到一些问题，导致无法正常工作。</p>
<p>为了解决这个问题，Python 提供了 multiprocessing 模块中的 <code>multiprocessing.Manager</code> 类，它允许在多进程环境中共享 Python 对象。这个类使用了一种特殊的代理对象来实现对象的共享和传递，从而规避了 pickle 在多进程中的限制。</p>
<p>因此，虽然在多进程环境中使用 pickle 可能会遇到一些问题，但通过使用 multiprocessing 模块中的管理器类，你仍然可以在多进程中有效地共享和传递 Python 对象。</p>
<p>比如如下代码：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> collections <span class="token keyword">import</span> defaultdict
<span class="token keyword">from</span> concurrent<span class="token punctuation">.</span>futures <span class="token keyword">import</span> ProcessPoolExecutor <span class="token keyword">as</span> Executor
<span class="token keyword">from</span> time <span class="token keyword">import</span> sleep

<span class="token keyword">from</span> time <span class="token keyword">import</span> sleep


<span class="token keyword">def</span> <span class="token function">report_progress</span><span class="token punctuation">(</span>futures<span class="token punctuation">,</span> tag<span class="token punctuation">,</span> callback<span class="token punctuation">)</span><span class="token punctuation">:</span>
    not_done <span class="token operator">=</span> <span class="token number">1</span>
    done <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">while</span> not_done <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span>
        not_done <span class="token operator">=</span> <span class="token number">0</span>
        done <span class="token operator">=</span> <span class="token number">0</span>
        <span class="token keyword">for</span> fut <span class="token keyword">in</span> futures<span class="token punctuation">:</span>
            <span class="token keyword">if</span> fut<span class="token punctuation">.</span>done<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                done <span class="token operator">+=</span><span class="token number">1</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                not_done <span class="token operator">+=</span> <span class="token number">1</span>
        sleep<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> not_done <span class="token operator">></span> <span class="token number">0</span> <span class="token operator">and</span> callback<span class="token punctuation">:</span>
            callback<span class="token punctuation">(</span>tag<span class="token punctuation">,</span> done<span class="token punctuation">,</span> not_done<span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">async_map</span><span class="token punctuation">(</span>executor<span class="token punctuation">,</span> mapper<span class="token punctuation">,</span> data<span class="token punctuation">)</span><span class="token punctuation">:</span>
    futures <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> datum <span class="token keyword">in</span> data<span class="token punctuation">:</span>
        futures<span class="token punctuation">.</span>append<span class="token punctuation">(</span>executor<span class="token punctuation">.</span>submit<span class="token punctuation">(</span>mapper<span class="token punctuation">,</span> datum<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> futures




<span class="token keyword">def</span> <span class="token function">map_reduce_less_naive</span><span class="token punctuation">(</span>my_input<span class="token punctuation">,</span> mapper<span class="token punctuation">,</span> reducer<span class="token punctuation">,</span> callback<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">with</span> Executor<span class="token punctuation">(</span>max_workers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token keyword">as</span> executor<span class="token punctuation">:</span>
        futures <span class="token operator">=</span> async_map<span class="token punctuation">(</span>executor<span class="token punctuation">,</span> mapper<span class="token punctuation">,</span> my_input<span class="token punctuation">)</span>
        report_progress<span class="token punctuation">(</span>futures<span class="token punctuation">,</span> <span class="token string">'map'</span><span class="token punctuation">,</span> callback<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true">#wait(futures).done</span>
        map_results <span class="token operator">=</span> map<span class="token punctuation">(</span><span class="token keyword">lambda</span> f<span class="token punctuation">:</span> f<span class="token punctuation">.</span>result<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> futures<span class="token punctuation">)</span>
        distributor <span class="token operator">=</span> defaultdict<span class="token punctuation">(</span>list<span class="token punctuation">)</span>
        <span class="token keyword">for</span> key<span class="token punctuation">,</span> value <span class="token keyword">in</span> map_results<span class="token punctuation">:</span>
            distributor<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>value<span class="token punctuation">)</span>

        futures <span class="token operator">=</span> async_map<span class="token punctuation">(</span>executor<span class="token punctuation">,</span> reducer<span class="token punctuation">,</span> distributor<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        report_progress<span class="token punctuation">(</span>futures<span class="token punctuation">,</span> <span class="token string">'reduce'</span><span class="token punctuation">,</span> callback<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true">#wait(futures).done</span>
        results <span class="token operator">=</span> map<span class="token punctuation">(</span><span class="token keyword">lambda</span> f<span class="token punctuation">:</span> f<span class="token punctuation">.</span>result<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> futures<span class="token punctuation">)</span>
    <span class="token keyword">return</span> results


<span class="token keyword">def</span> <span class="token function">emitter</span><span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true">#sleep(10)</span>
    <span class="token keyword">return</span> word<span class="token punctuation">,</span> <span class="token number">1</span>


counter <span class="token operator">=</span> <span class="token keyword">lambda</span> emitted<span class="token punctuation">:</span> <span class="token punctuation">(</span>emitted<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> sum<span class="token punctuation">(</span>emitted<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">reporter</span><span class="token punctuation">(</span>tag<span class="token punctuation">,</span> done<span class="token punctuation">,</span> not_done<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'Operation {tag}: {done}/{done+not_done}'</span><span class="token punctuation">)</span>

words <span class="token operator">=</span> <span class="token string">'Python is great Python rocks'</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span>
a <span class="token operator">=</span> map_reduce_less_naive<span class="token punctuation">(</span>words<span class="token punctuation">,</span> emitter<span class="token punctuation">,</span> counter<span class="token punctuation">,</span> reporter<span class="token punctuation">)</span>

<span class="token keyword">for</span> i <span class="token keyword">in</span> sorted<span class="token punctuation">(</span>a<span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>报错如下：</p>
<pre class="line-numbers language-python"><code class="language-python">Traceback <span class="token punctuation">(</span>most recent call last<span class="token punctuation">)</span><span class="token punctuation">:</span>
  File <span class="token string">"/usr/lib64/python3.9/multiprocessing/queues.py"</span><span class="token punctuation">,</span> line <span class="token number">244</span><span class="token punctuation">,</span> <span class="token keyword">in</span> _feed
    obj <span class="token operator">=</span> _ForkingPickler<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>obj<span class="token punctuation">)</span>
  File <span class="token string">"/usr/lib64/python3.9/multiprocessing/reduction.py"</span><span class="token punctuation">,</span> line <span class="token number">51</span><span class="token punctuation">,</span> <span class="token keyword">in</span> dumps
    cls<span class="token punctuation">(</span>buf<span class="token punctuation">,</span> protocol<span class="token punctuation">)</span><span class="token punctuation">.</span>dump<span class="token punctuation">(</span>obj<span class="token punctuation">)</span>
_pickle<span class="token punctuation">.</span>PicklingError<span class="token punctuation">:</span> Can't pickle <span class="token operator">&lt;</span>function <span class="token operator">&lt;</span><span class="token keyword">lambda</span><span class="token operator">></span> at <span class="token number">0x7efcde37d8b0</span><span class="token operator">></span><span class="token punctuation">:</span> attribute lookup <span class="token operator">&lt;</span><span class="token keyword">lambda</span><span class="token operator">></span> on __main__ failed

The above exception was the direct cause of the following exception<span class="token punctuation">:</span>

Traceback <span class="token punctuation">(</span>most recent call last<span class="token punctuation">)</span><span class="token punctuation">:</span>
  File <span class="token string">"/root/m_m.py"</span><span class="token punctuation">,</span> line <span class="token number">63</span><span class="token punctuation">,</span> <span class="token keyword">in</span> <span class="token operator">&lt;</span>module<span class="token operator">></span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> sorted<span class="token punctuation">(</span>a<span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
  File <span class="token string">"/root/m_m.py"</span><span class="token punctuation">,</span> line <span class="token number">46</span><span class="token punctuation">,</span> <span class="token keyword">in</span> <span class="token operator">&lt;</span><span class="token keyword">lambda</span><span class="token operator">></span>
    results <span class="token operator">=</span> map<span class="token punctuation">(</span><span class="token keyword">lambda</span> f<span class="token punctuation">:</span> f<span class="token punctuation">.</span>result<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> futures<span class="token punctuation">)</span>
  File <span class="token string">"/usr/lib64/python3.9/concurrent/futures/_base.py"</span><span class="token punctuation">,</span> line <span class="token number">439</span><span class="token punctuation">,</span> <span class="token keyword">in</span> result
    <span class="token keyword">return</span> self<span class="token punctuation">.</span>__get_result<span class="token punctuation">(</span><span class="token punctuation">)</span>
  File <span class="token string">"/usr/lib64/python3.9/concurrent/futures/_base.py"</span><span class="token punctuation">,</span> line <span class="token number">391</span><span class="token punctuation">,</span> <span class="token keyword">in</span> __get_result
    <span class="token keyword">raise</span> self<span class="token punctuation">.</span>_exception
  File <span class="token string">"/usr/lib64/python3.9/multiprocessing/queues.py"</span><span class="token punctuation">,</span> line <span class="token number">244</span><span class="token punctuation">,</span> <span class="token keyword">in</span> _feed
    obj <span class="token operator">=</span> _ForkingPickler<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>obj<span class="token punctuation">)</span>
  File <span class="token string">"/usr/lib64/python3.9/multiprocessing/reduction.py"</span><span class="token punctuation">,</span> line <span class="token number">51</span><span class="token punctuation">,</span> <span class="token keyword">in</span> dumps
    cls<span class="token punctuation">(</span>buf<span class="token punctuation">,</span> protocol<span class="token punctuation">)</span><span class="token punctuation">.</span>dump<span class="token punctuation">(</span>obj<span class="token punctuation">)</span>
_pickle<span class="token punctuation">.</span>PicklingError<span class="token punctuation">:</span> Can't pickle <span class="token operator">&lt;</span>function <span class="token operator">&lt;</span><span class="token keyword">lambda</span><span class="token operator">></span> at <span class="token number">0x7efcde37d8b0</span><span class="token operator">></span><span class="token punctuation">:</span> attribute lookup <span class="token operator">&lt;</span><span class="token keyword">lambda</span><span class="token operator">></span> on __main__ failed
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这个错误表明在尝试将任务提交给子进程时出现了 pickling 错误，具体原因是无法 pickle lambda 函数。Lambda 函数通常无法序列化，因为它们在序列化时无法被正常地识别和重建。</p>
<p>修改如下：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> collections <span class="token keyword">import</span> defaultdict
<span class="token keyword">from</span> concurrent<span class="token punctuation">.</span>futures <span class="token keyword">import</span> ProcessPoolExecutor <span class="token keyword">as</span> Executor
<span class="token keyword">from</span> time <span class="token keyword">import</span> sleep


<span class="token keyword">def</span> <span class="token function">report_progress</span><span class="token punctuation">(</span>futures<span class="token punctuation">,</span> tag<span class="token punctuation">,</span> callback<span class="token punctuation">)</span><span class="token punctuation">:</span>
    not_done <span class="token operator">=</span> <span class="token number">1</span>
    done <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">while</span> not_done <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span>
        not_done <span class="token operator">=</span> <span class="token number">0</span>
        done <span class="token operator">=</span> <span class="token number">0</span>
        <span class="token keyword">for</span> fut <span class="token keyword">in</span> futures<span class="token punctuation">:</span>
            <span class="token keyword">if</span> fut<span class="token punctuation">.</span>done<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                done <span class="token operator">+=</span><span class="token number">1</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                not_done <span class="token operator">+=</span> <span class="token number">1</span>
        sleep<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> not_done <span class="token operator">></span> <span class="token number">0</span> <span class="token operator">and</span> callback<span class="token punctuation">:</span>
            callback<span class="token punctuation">(</span>tag<span class="token punctuation">,</span> done<span class="token punctuation">,</span> not_done<span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">async_map</span><span class="token punctuation">(</span>executor<span class="token punctuation">,</span> mapper<span class="token punctuation">,</span> data<span class="token punctuation">)</span><span class="token punctuation">:</span>
    futures <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> datum <span class="token keyword">in</span> data<span class="token punctuation">:</span>
        futures<span class="token punctuation">.</span>append<span class="token punctuation">(</span>executor<span class="token punctuation">.</span>submit<span class="token punctuation">(</span>mapper<span class="token punctuation">,</span> datum<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> futures




<span class="token keyword">def</span> <span class="token function">map_reduce_less_naive</span><span class="token punctuation">(</span>my_input<span class="token punctuation">,</span> mapper<span class="token punctuation">,</span> reducer<span class="token punctuation">,</span> callback<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">with</span> Executor<span class="token punctuation">(</span>max_workers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token keyword">as</span> executor<span class="token punctuation">:</span>
        futures <span class="token operator">=</span> async_map<span class="token punctuation">(</span>executor<span class="token punctuation">,</span> mapper<span class="token punctuation">,</span> my_input<span class="token punctuation">)</span>
        report_progress<span class="token punctuation">(</span>futures<span class="token punctuation">,</span> <span class="token string">'map'</span><span class="token punctuation">,</span> callback<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true">#wait(futures).done</span>
        map_results <span class="token operator">=</span> map<span class="token punctuation">(</span><span class="token keyword">lambda</span> f<span class="token punctuation">:</span> f<span class="token punctuation">.</span>result<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> futures<span class="token punctuation">)</span>
        distributor <span class="token operator">=</span> defaultdict<span class="token punctuation">(</span>list<span class="token punctuation">)</span>
        <span class="token keyword">for</span> key<span class="token punctuation">,</span> value <span class="token keyword">in</span> map_results<span class="token punctuation">:</span>
            distributor<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>value<span class="token punctuation">)</span>

        futures <span class="token operator">=</span> async_map<span class="token punctuation">(</span>executor<span class="token punctuation">,</span> reducer<span class="token punctuation">,</span> distributor<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        report_progress<span class="token punctuation">(</span>futures<span class="token punctuation">,</span> <span class="token string">'reduce'</span><span class="token punctuation">,</span> callback<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true">#wait(futures).done</span>
        results <span class="token operator">=</span> map<span class="token punctuation">(</span><span class="token keyword">lambda</span> f<span class="token punctuation">:</span> f<span class="token punctuation">.</span>result<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> futures<span class="token punctuation">)</span>
    <span class="token keyword">return</span> results


<span class="token keyword">def</span> <span class="token function">emitter</span><span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true">#sleep(10)</span>
    <span class="token keyword">return</span> word<span class="token punctuation">,</span> <span class="token number">1</span>




<span class="token keyword">def</span> <span class="token function">counter</span><span class="token punctuation">(</span>emitted<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> emitted<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> sum<span class="token punctuation">(</span>emitted<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">reporter</span><span class="token punctuation">(</span>tag<span class="token punctuation">,</span> done<span class="token punctuation">,</span> not_done<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'Operation {tag}: {done}/{done+not_done}'</span><span class="token punctuation">)</span>

words <span class="token operator">=</span> <span class="token string">'Python is great Python rocks'</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span>
a <span class="token operator">=</span> map_reduce_less_naive<span class="token punctuation">(</span>words<span class="token punctuation">,</span> emitter<span class="token punctuation">,</span> counter<span class="token punctuation">,</span> reporter<span class="token punctuation">)</span>

<span class="token keyword">for</span> i <span class="token keyword">in</span> sorted<span class="token punctuation">(</span>a<span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h4 id="CPU-count-vs-sched-getaffinity-to-determine-the-pool-size"><a href="#CPU-count-vs-sched-getaffinity-to-determine-the-pool-size" class="headerlink" title="CPU_count vs. sched_getaffinity to determine the pool size"></a>CPU_count vs. sched_getaffinity to determine the pool size</h4><p>cpu_count 取值是CPU的逻辑核心数</p>
<pre class="line-numbers language-bash"><code class="language-bash">Help on built-in <span class="token keyword">function</span> sched_getaffinity <span class="token keyword">in</span> module posix:

sched_getaffinity<span class="token punctuation">(</span>pid, /<span class="token punctuation">)</span>
    Return the affinity of the process identified by pid <span class="token punctuation">(</span>or the current process <span class="token keyword">if</span> zero<span class="token punctuation">)</span>.
    
    The affinity is returned as a <span class="token keyword">set</span> of CPU identifiers.
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>os.sched_getaffinity()&#96; 函数返回分配给当前进程的CPU核心集合。在多核系统中，这通常是一个包含了当前进程可以运行的CPU核心的集合。每个核心都有一个唯一的标识符，这些标识符通常是整数。</p>
<p>注意，这个函数返回的核心集合通常是系统分配给你的核心数。但是，在特定情况下，这可能会受到系统配置、权限限制或其他因素的影响。比如虚拟机，容器，系统的限制。</p>
<h3 id="多进程版本mapreduce"><a href="#多进程版本mapreduce" class="headerlink" title="多进程版本mapreduce"></a>多进程版本mapreduce</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> collections <span class="token keyword">import</span> defaultdict
<span class="token keyword">from</span> concurrent<span class="token punctuation">.</span>futures <span class="token keyword">import</span> ProcessPoolExecutor <span class="token keyword">as</span> Executor
<span class="token keyword">from</span> time <span class="token keyword">import</span> sleep


<span class="token keyword">def</span> <span class="token function">report_progress</span><span class="token punctuation">(</span>futures<span class="token punctuation">,</span> tag<span class="token punctuation">,</span> callback<span class="token punctuation">)</span><span class="token punctuation">:</span>
    not_done <span class="token operator">=</span> <span class="token number">1</span>
    done <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">while</span> not_done <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span>
        not_done <span class="token operator">=</span> <span class="token number">0</span>
        done <span class="token operator">=</span> <span class="token number">0</span>
        <span class="token keyword">for</span> fut <span class="token keyword">in</span> futures<span class="token punctuation">:</span>
            <span class="token keyword">if</span> fut<span class="token punctuation">.</span>done<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                done <span class="token operator">+=</span><span class="token number">1</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                not_done <span class="token operator">+=</span> <span class="token number">1</span>
        sleep<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> callback<span class="token punctuation">:</span>
            callback<span class="token punctuation">(</span>tag<span class="token punctuation">,</span> done<span class="token punctuation">,</span> not_done<span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">async_map</span><span class="token punctuation">(</span>executor<span class="token punctuation">,</span> mapper<span class="token punctuation">,</span> data<span class="token punctuation">)</span><span class="token punctuation">:</span>
    futures <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> datum <span class="token keyword">in</span> data<span class="token punctuation">:</span>
        futures<span class="token punctuation">.</span>append<span class="token punctuation">(</span>executor<span class="token punctuation">.</span>submit<span class="token punctuation">(</span>mapper<span class="token punctuation">,</span> datum<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> futures


<span class="token keyword">def</span> <span class="token function">map_less_naive</span><span class="token punctuation">(</span>executor<span class="token punctuation">,</span> my_input<span class="token punctuation">,</span> mapper<span class="token punctuation">)</span><span class="token punctuation">:</span>
    map_results <span class="token operator">=</span> async_map<span class="token punctuation">(</span>executor<span class="token punctuation">,</span> mapper<span class="token punctuation">,</span> my_input<span class="token punctuation">)</span>
    <span class="token keyword">return</span> map_results


<span class="token keyword">def</span> <span class="token function">map_reduce_less_naive</span><span class="token punctuation">(</span>my_input<span class="token punctuation">,</span> mapper<span class="token punctuation">,</span> reducer<span class="token punctuation">,</span> callback<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">with</span> Executor<span class="token punctuation">(</span>max_workers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token keyword">as</span> executor<span class="token punctuation">:</span>
        futures <span class="token operator">=</span> async_map<span class="token punctuation">(</span>executor<span class="token punctuation">,</span> mapper<span class="token punctuation">,</span> my_input<span class="token punctuation">)</span>
        report_progress<span class="token punctuation">(</span>futures<span class="token punctuation">,</span> <span class="token string">'map'</span><span class="token punctuation">,</span> callback<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true">#wait(futures).done</span>
        map_results <span class="token operator">=</span> map<span class="token punctuation">(</span><span class="token keyword">lambda</span> f<span class="token punctuation">:</span> f<span class="token punctuation">.</span>result<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> futures<span class="token punctuation">)</span>
        distributor <span class="token operator">=</span> defaultdict<span class="token punctuation">(</span>list<span class="token punctuation">)</span>
        <span class="token keyword">for</span> key<span class="token punctuation">,</span> value <span class="token keyword">in</span> map_results<span class="token punctuation">:</span>
            distributor<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>value<span class="token punctuation">)</span>

        futures <span class="token operator">=</span> async_map<span class="token punctuation">(</span>executor<span class="token punctuation">,</span> reducer<span class="token punctuation">,</span> distributor<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        report_progress<span class="token punctuation">(</span>futures<span class="token punctuation">,</span> <span class="token string">'reduce'</span><span class="token punctuation">,</span> callback<span class="token punctuation">)</span>
        results <span class="token operator">=</span> map<span class="token punctuation">(</span><span class="token keyword">lambda</span> f<span class="token punctuation">:</span> f<span class="token punctuation">.</span>result<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> futures<span class="token punctuation">)</span>
    <span class="token keyword">return</span> results


<span class="token keyword">def</span> <span class="token function">emitter</span><span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> word<span class="token punctuation">,</span> <span class="token number">1</span>


<span class="token keyword">def</span> <span class="token function">counter</span><span class="token punctuation">(</span>emitted<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> emitted<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> sum<span class="token punctuation">(</span>emitted<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">reporter</span><span class="token punctuation">(</span>tag<span class="token punctuation">,</span> done<span class="token punctuation">,</span> not_done<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'Operation {tag}: {done}/{done+not_done}'</span><span class="token punctuation">)</span>

words <span class="token operator">=</span> <span class="token string">'Python is great Python rocks'</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span>
a <span class="token operator">=</span> map_reduce_less_naive<span class="token punctuation">(</span>words<span class="token punctuation">,</span> emitter<span class="token punctuation">,</span> counter<span class="token punctuation">,</span> reporter<span class="token punctuation">)</span>

<span class="token keyword">for</span> i <span class="token keyword">in</span> sorted<span class="token punctuation">(</span>a<span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>使用chunk分块读取数据:</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> collections <span class="token keyword">import</span> defaultdict
<span class="token keyword">import</span> multiprocessing <span class="token keyword">as</span> mp
<span class="token keyword">import</span> sys
<span class="token keyword">from</span> time <span class="token keyword">import</span> sleep


<span class="token keyword">def</span> <span class="token function">report_progress</span><span class="token punctuation">(</span>map_returns<span class="token punctuation">,</span> tag<span class="token punctuation">,</span> callback<span class="token punctuation">)</span><span class="token punctuation">:</span>
    done <span class="token operator">=</span> <span class="token number">0</span>
    num_jobs <span class="token operator">=</span> len<span class="token punctuation">(</span>map_returns<span class="token punctuation">)</span>
    <span class="token keyword">while</span> num_jobs <span class="token operator">></span> done<span class="token punctuation">:</span>
        done <span class="token operator">=</span> <span class="token number">0</span>
        <span class="token keyword">for</span> ret <span class="token keyword">in</span> map_returns<span class="token punctuation">:</span>
            <span class="token keyword">if</span> ret<span class="token punctuation">.</span>ready<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                done <span class="token operator">+=</span> <span class="token number">1</span>
        sleep<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> callback<span class="token punctuation">:</span>
            callback<span class="token punctuation">(</span>tag<span class="token punctuation">,</span> done<span class="token punctuation">,</span> num_jobs <span class="token operator">-</span> done<span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">chunk0</span><span class="token punctuation">(</span>my_list<span class="token punctuation">,</span> chunk_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>my_list<span class="token punctuation">)</span><span class="token punctuation">,</span> chunk_size<span class="token punctuation">)</span><span class="token punctuation">:</span>   <span class="token comment" spellcheck="true">#requires a list</span>
        <span class="token keyword">yield</span> my_list<span class="token punctuation">[</span>i<span class="token punctuation">:</span>i <span class="token operator">+</span> chunk_size<span class="token punctuation">]</span>


<span class="token keyword">def</span> <span class="token function">chunk</span><span class="token punctuation">(</span>my_iter<span class="token punctuation">,</span> chunk_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
    chunk_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> elem <span class="token keyword">in</span> my_iter<span class="token punctuation">:</span>
        chunk_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>elem<span class="token punctuation">)</span>
        <span class="token keyword">if</span> len<span class="token punctuation">(</span>chunk_list<span class="token punctuation">)</span> <span class="token operator">==</span> chunk_size<span class="token punctuation">:</span>
            <span class="token keyword">yield</span> chunk_list
            chunk_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">if</span> len<span class="token punctuation">(</span>chunk_list<span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span>
        <span class="token keyword">yield</span> chunk_list


<span class="token keyword">def</span> <span class="token function">chunk_runner</span><span class="token punctuation">(</span>fun<span class="token punctuation">,</span> data<span class="token punctuation">)</span><span class="token punctuation">:</span>
    ret <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> datum <span class="token keyword">in</span> data<span class="token punctuation">:</span>
        ret<span class="token punctuation">.</span>append<span class="token punctuation">(</span>fun<span class="token punctuation">(</span>datum<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> ret

<span class="token keyword">def</span> <span class="token function">chunked_async_map</span><span class="token punctuation">(</span>pool<span class="token punctuation">,</span> mapper<span class="token punctuation">,</span> data<span class="token punctuation">,</span> chunk_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
    async_returns <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> data_part <span class="token keyword">in</span> chunk<span class="token punctuation">(</span>data<span class="token punctuation">,</span> chunk_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
        async_returns<span class="token punctuation">.</span>append<span class="token punctuation">(</span>pool<span class="token punctuation">.</span>apply_async<span class="token punctuation">(</span>
            chunk_runner<span class="token punctuation">,</span> <span class="token punctuation">(</span>mapper<span class="token punctuation">,</span> data_part<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#RUNNER</span>
    <span class="token keyword">return</span> async_returns


<span class="token keyword">def</span> <span class="token function">map_reduce</span><span class="token punctuation">(</span>pool<span class="token punctuation">,</span> my_input<span class="token punctuation">,</span> mapper<span class="token punctuation">,</span> reducer<span class="token punctuation">,</span> chunk_size<span class="token punctuation">,</span> callback<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment" spellcheck="true">#XXX</span>
    map_returns <span class="token operator">=</span> chunked_async_map<span class="token punctuation">(</span>pool<span class="token punctuation">,</span> mapper<span class="token punctuation">,</span> my_input<span class="token punctuation">,</span> chunk_size<span class="token punctuation">)</span>
    report_progress<span class="token punctuation">(</span>map_returns<span class="token punctuation">,</span> <span class="token string">'map'</span><span class="token punctuation">,</span> callback<span class="token punctuation">)</span>
    map_results <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> ret <span class="token keyword">in</span> map_returns<span class="token punctuation">:</span>
        map_results<span class="token punctuation">.</span>extend<span class="token punctuation">(</span>ret<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true"># EXTEND</span>
    distributor <span class="token operator">=</span> defaultdict<span class="token punctuation">(</span>list<span class="token punctuation">)</span>
    <span class="token keyword">for</span> key<span class="token punctuation">,</span> value <span class="token keyword">in</span> map_results<span class="token punctuation">:</span>
        distributor<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>value<span class="token punctuation">)</span>
    returns <span class="token operator">=</span> chunked_async_map<span class="token punctuation">(</span>pool<span class="token punctuation">,</span> reducer<span class="token punctuation">,</span> distributor<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> chunk_size<span class="token punctuation">)</span>
    report_progress<span class="token punctuation">(</span>returns<span class="token punctuation">,</span> <span class="token string">'reduce'</span><span class="token punctuation">,</span> callback<span class="token punctuation">)</span>
    results <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> ret <span class="token keyword">in</span> returns<span class="token punctuation">:</span>
        results<span class="token punctuation">.</span>extend<span class="token punctuation">(</span>ret<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> results


<span class="token keyword">def</span> <span class="token function">emitter</span><span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> word<span class="token punctuation">,</span> <span class="token number">1</span>


<span class="token keyword">def</span> <span class="token function">counter</span><span class="token punctuation">(</span>emitted<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> emitted<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> sum<span class="token punctuation">(</span>emitted<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">reporter</span><span class="token punctuation">(</span>tag<span class="token punctuation">,</span> done<span class="token punctuation">,</span> not_done<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'Operation {tag}: {done}/{done+not_done}'</span><span class="token punctuation">)</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    words <span class="token operator">=</span> <span class="token punctuation">[</span>word
             <span class="token keyword">for</span> word <span class="token keyword">in</span> map<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>rstrip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                             <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>open<span class="token punctuation">(</span><span class="token string">'text.txt'</span><span class="token punctuation">,</span> <span class="token string">'rt'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
             <span class="token keyword">if</span> word <span class="token operator">!=</span> <span class="token string">''</span> <span class="token punctuation">]</span>

    chunk_size <span class="token operator">=</span> int<span class="token punctuation">(</span>sys<span class="token punctuation">.</span>argv<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    pool <span class="token operator">=</span> mp<span class="token punctuation">.</span>Pool<span class="token punctuation">(</span><span class="token punctuation">)</span>
    counts <span class="token operator">=</span> map_reduce<span class="token punctuation">(</span>pool<span class="token punctuation">,</span> words<span class="token punctuation">,</span> emitter<span class="token punctuation">,</span> counter<span class="token punctuation">,</span> chunk_size<span class="token punctuation">,</span> reporter<span class="token punctuation">)</span>
    pool<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
    pool<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">for</span> count <span class="token keyword">in</span> sorted<span class="token punctuation">(</span>counts<span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>count<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>不同的块大小运行效率:</p>
<pre><code>$ time python3 chunk.py 10     
Operation map: 1047/35281
Operation map: 3470/35281
Operation map: 8337/35281
Operation map: 11402/35281
Operation map: 13680/35281
Operation map: 15751/35281
Operation map: 17484/35281
Operation map: 19155/35281
Operation map: 22504/35281
Operation map: 25469/35281
Operation map: 29450/35281
Operation map: 32024/35281
Operation map: 33468/35281
Operation map: 35281/35281
Operation reduce: 26/2923
Operation reduce: 2211/2923
Operation reduce: 2923/2923
python3 chunk.py 10  9.34s user 2.79s system 96% cpu 12.523 total

$ time python3 chunk.py 100
Operation map: 208/3529
Operation map: 1358/3529
Operation map: 3139/3529
Operation map: 3529/3529
Operation reduce: 8/293
Operation reduce: 293/293
python3 chunk.py 100  2.32s user 0.75s system 72% cpu 4.269 total

$ time python3 chunk.py 1000
Operation map: 39/353
Operation map: 325/353
Operation map: 353/353
Operation reduce: 0/30
Operation reduce: 30/30
python3 chunk.py 1000  1.50s user 0.49s system 48% cpu 4.078 total

$ time python3 chunk.py 10000
Operation map: 7/36
Operation map: 36/36
Operation reduce: 0/3
Operation reduce: 3/3
python3 chunk.py 10000  1.69s user 0.29s system 41% cpu 4.802 total

$ time python3 chunk.py 100000
Operation map: 0/4
Operation map: 4/4
Operation reduce: 0/1
Operation reduce: 1/1
python3 chunk.py 100000  1.52s user 0.31s system 47% cpu 3.865 total

$ time python3 chunk.py 1000000
Operation map: 0/1
Operation map: 0/1
Operation map: 1/1
Operation reduce: 0/1
Operation reduce: 1/1
python3 chunk.py 1000000  1.77s user 0.30s system 55% cpu 3.722 total
</code></pre>
<p>整合服务器和计算功能:</p>
<p>server.py</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> asyncio
<span class="token keyword">import</span> marshal
<span class="token keyword">import</span> multiprocessing <span class="token keyword">as</span> mp
<span class="token keyword">import</span> pickle
<span class="token keyword">from</span> queue <span class="token keyword">import</span> Empty<span class="token punctuation">,</span> Queue  <span class="token comment" spellcheck="true"># &lt;XXX> PriorityQueue</span>
<span class="token keyword">import</span> threading
<span class="token keyword">import</span> types

<span class="token keyword">import</span> chunk_mp_mapreduce <span class="token keyword">as</span> mr


<span class="token comment" spellcheck="true"># &lt;XXX> multiprocessing.Queue</span>

work_queue <span class="token operator">=</span> Queue<span class="token punctuation">(</span><span class="token punctuation">)</span>
results_queue <span class="token operator">=</span> Queue<span class="token punctuation">(</span><span class="token punctuation">)</span>
results <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>

<span class="token keyword">async</span> <span class="token keyword">def</span> <span class="token function">submit_job</span><span class="token punctuation">(</span>job_id<span class="token punctuation">,</span> reader<span class="token punctuation">,</span> writer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    writer<span class="token punctuation">.</span>write<span class="token punctuation">(</span>job_id<span class="token punctuation">.</span>to_bytes<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token string">'little'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
    code_size <span class="token operator">=</span> int<span class="token punctuation">.</span>from_bytes<span class="token punctuation">(</span><span class="token keyword">await</span> reader<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'little'</span><span class="token punctuation">)</span>
    my_code <span class="token operator">=</span> marshal<span class="token punctuation">.</span>loads<span class="token punctuation">(</span><span class="token keyword">await</span> reader<span class="token punctuation">.</span>read<span class="token punctuation">(</span>code_size<span class="token punctuation">)</span><span class="token punctuation">)</span>
    data_size <span class="token operator">=</span> int<span class="token punctuation">.</span>from_bytes<span class="token punctuation">(</span><span class="token keyword">await</span> reader<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'little'</span><span class="token punctuation">)</span>
    data <span class="token operator">=</span> pickle<span class="token punctuation">.</span>loads<span class="token punctuation">(</span><span class="token keyword">await</span> reader<span class="token punctuation">.</span>read<span class="token punctuation">(</span>data_size<span class="token punctuation">)</span><span class="token punctuation">)</span>
    work_queue<span class="token punctuation">.</span>put_nowait<span class="token punctuation">(</span><span class="token punctuation">(</span>job_id<span class="token punctuation">,</span> my_code<span class="token punctuation">,</span> data<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># &lt;XXX> Data not very efficient, no_wait and queue size</span>


<span class="token keyword">def</span> <span class="token function">get_results_queue</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">while</span> results_queue<span class="token punctuation">.</span>qsize<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span>   <span class="token comment" spellcheck="true"># &lt;XXX> Not assured</span>
        <span class="token keyword">try</span><span class="token punctuation">:</span>
            job_id<span class="token punctuation">,</span> data <span class="token operator">=</span> results_queue<span class="token punctuation">.</span>get_nowait<span class="token punctuation">(</span><span class="token punctuation">)</span>
            results<span class="token punctuation">[</span>job_id<span class="token punctuation">]</span> <span class="token operator">=</span> data
        <span class="token keyword">except</span> Empty<span class="token punctuation">:</span>
            <span class="token keyword">return</span>


<span class="token keyword">async</span> <span class="token keyword">def</span> <span class="token function">get_results</span><span class="token punctuation">(</span>reader<span class="token punctuation">,</span> writer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    get_results_queue<span class="token punctuation">(</span><span class="token punctuation">)</span>
    job_id <span class="token operator">=</span> int<span class="token punctuation">.</span>from_bytes<span class="token punctuation">(</span><span class="token keyword">await</span> reader<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'little'</span><span class="token punctuation">)</span>
    data <span class="token operator">=</span> pickle<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>None<span class="token punctuation">)</span>
    <span class="token keyword">if</span> job_id <span class="token keyword">in</span> results<span class="token punctuation">:</span>
        data <span class="token operator">=</span> pickle<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>results<span class="token punctuation">[</span>job_id<span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">del</span> results<span class="token punctuation">[</span>job_id<span class="token punctuation">]</span>
    writer<span class="token punctuation">.</span>write<span class="token punctuation">(</span>len<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">.</span>to_bytes<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token string">'little'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    writer<span class="token punctuation">.</span>write<span class="token punctuation">(</span>data<span class="token punctuation">)</span>


<span class="token keyword">async</span> <span class="token keyword">def</span> <span class="token function">accept_requests</span><span class="token punctuation">(</span>reader<span class="token punctuation">,</span> writer<span class="token punctuation">,</span> job_id<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    op <span class="token operator">=</span> <span class="token keyword">await</span> reader<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> op<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        <span class="token keyword">await</span> submit_job<span class="token punctuation">(</span>job_id<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> reader<span class="token punctuation">,</span> writer<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># XXX Errors in async</span>
        job_id<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>
    <span class="token keyword">elif</span> op<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
        <span class="token keyword">await</span> get_results<span class="token punctuation">(</span>reader<span class="token punctuation">,</span> writer<span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">worker</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment" spellcheck="true"># daemon</span>
    pool <span class="token operator">=</span> mp<span class="token punctuation">.</span>Pool<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>
        job_id<span class="token punctuation">,</span> code<span class="token punctuation">,</span> data <span class="token operator">=</span> work_queue<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># blocking</span>
        func <span class="token operator">=</span> types<span class="token punctuation">.</span>FunctionType<span class="token punctuation">(</span>code<span class="token punctuation">,</span> globals<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'mapper_and_reducer'</span><span class="token punctuation">)</span>
        mapper<span class="token punctuation">,</span> reducer <span class="token operator">=</span> func<span class="token punctuation">(</span><span class="token punctuation">)</span>
        counts <span class="token operator">=</span> mr<span class="token punctuation">.</span>map_reduce<span class="token punctuation">(</span>pool<span class="token punctuation">,</span> data<span class="token punctuation">,</span> mapper<span class="token punctuation">,</span> reducer<span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> mr<span class="token punctuation">.</span>reporter<span class="token punctuation">)</span>
        results_queue<span class="token punctuation">.</span>put<span class="token punctuation">(</span><span class="token punctuation">(</span>job_id<span class="token punctuation">,</span> counts<span class="token punctuation">)</span><span class="token punctuation">)</span>
    pool<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
    pool<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">)</span>


<span class="token keyword">async</span> <span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    server <span class="token operator">=</span> <span class="token keyword">await</span> asyncio<span class="token punctuation">.</span>start_server<span class="token punctuation">(</span>accept_requests<span class="token punctuation">,</span> <span class="token string">'127.0.0.1'</span><span class="token punctuation">,</span> <span class="token number">1936</span><span class="token punctuation">)</span>
    worker_thread <span class="token operator">=</span> threading<span class="token punctuation">.</span>Thread<span class="token punctuation">(</span>target<span class="token operator">=</span>worker<span class="token punctuation">)</span>   <span class="token comment" spellcheck="true"># &lt;XXX> Daemon</span>
    worker_thread<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">async</span> <span class="token keyword">with</span> server<span class="token punctuation">:</span>
        <span class="token keyword">await</span> server<span class="token punctuation">.</span>serve_forever<span class="token punctuation">(</span><span class="token punctuation">)</span>


asyncio<span class="token punctuation">.</span>run<span class="token punctuation">(</span>main<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>chunk_mp_mapreduce.py</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> collections <span class="token keyword">import</span> defaultdict
<span class="token keyword">import</span> marshal
<span class="token keyword">import</span> multiprocessing <span class="token keyword">as</span> mp
<span class="token keyword">import</span> sys
<span class="token keyword">from</span> time <span class="token keyword">import</span> sleep
<span class="token keyword">import</span> types


<span class="token keyword">def</span> <span class="token function">report_progress</span><span class="token punctuation">(</span>map_returns<span class="token punctuation">,</span> tag<span class="token punctuation">,</span> callback<span class="token punctuation">)</span><span class="token punctuation">:</span>
    done <span class="token operator">=</span> <span class="token number">0</span>
    num_jobs <span class="token operator">=</span> len<span class="token punctuation">(</span>map_returns<span class="token punctuation">)</span>
    <span class="token keyword">while</span> num_jobs <span class="token operator">></span> done<span class="token punctuation">:</span>
        done <span class="token operator">=</span> <span class="token number">0</span>
        <span class="token keyword">for</span> ret <span class="token keyword">in</span> map_returns<span class="token punctuation">:</span>
            <span class="token keyword">if</span> ret<span class="token punctuation">.</span>ready<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                done <span class="token operator">+=</span> <span class="token number">1</span>
        sleep<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> callback<span class="token punctuation">:</span>
            callback<span class="token punctuation">(</span>tag<span class="token punctuation">,</span> done<span class="token punctuation">,</span> num_jobs <span class="token operator">-</span> done<span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">chunk0</span><span class="token punctuation">(</span>my_list<span class="token punctuation">,</span> chunk_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>my_list<span class="token punctuation">)</span><span class="token punctuation">,</span> chunk_size<span class="token punctuation">)</span><span class="token punctuation">:</span>   <span class="token comment" spellcheck="true">#requires a list</span>
        <span class="token keyword">yield</span> my_list<span class="token punctuation">[</span>i<span class="token punctuation">:</span>i <span class="token operator">+</span> chunk_size<span class="token punctuation">]</span>


<span class="token keyword">def</span> <span class="token function">chunk</span><span class="token punctuation">(</span>my_iter<span class="token punctuation">,</span> chunk_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
    chunk_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> elem <span class="token keyword">in</span> my_iter<span class="token punctuation">:</span>
        chunk_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>elem<span class="token punctuation">)</span>
        <span class="token keyword">if</span> len<span class="token punctuation">(</span>chunk_list<span class="token punctuation">)</span> <span class="token operator">==</span> chunk_size<span class="token punctuation">:</span>
            <span class="token keyword">yield</span> chunk_list
            chunk_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">if</span> len<span class="token punctuation">(</span>chunk_list<span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span>
        <span class="token keyword">yield</span> chunk_list


<span class="token keyword">def</span> <span class="token function">chunk_runner</span><span class="token punctuation">(</span>fun_marshal<span class="token punctuation">,</span> data<span class="token punctuation">)</span><span class="token punctuation">:</span>
    fun <span class="token operator">=</span> types<span class="token punctuation">.</span>FunctionType<span class="token punctuation">(</span>marshal<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>fun_marshal<span class="token punctuation">)</span><span class="token punctuation">,</span> globals<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'fun'</span><span class="token punctuation">)</span>
    ret <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> datum <span class="token keyword">in</span> data<span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>fun<span class="token punctuation">(</span>datum<span class="token punctuation">)</span><span class="token punctuation">)</span>
        ret<span class="token punctuation">.</span>append<span class="token punctuation">(</span>fun<span class="token punctuation">(</span>datum<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> ret

<span class="token keyword">def</span> <span class="token function">chunked_async_map</span><span class="token punctuation">(</span>pool<span class="token punctuation">,</span> mapper<span class="token punctuation">,</span> data<span class="token punctuation">,</span> chunk_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
    async_returns <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> data_part <span class="token keyword">in</span> chunk<span class="token punctuation">(</span>data<span class="token punctuation">,</span> chunk_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
        async_returns<span class="token punctuation">.</span>append<span class="token punctuation">(</span>pool<span class="token punctuation">.</span>apply_async<span class="token punctuation">(</span>
            chunk_runner<span class="token punctuation">,</span> <span class="token punctuation">(</span>marshal<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>mapper<span class="token punctuation">.</span>__code__<span class="token punctuation">)</span><span class="token punctuation">,</span> data_part<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> async_returns


<span class="token keyword">def</span> <span class="token function">map_reduce</span><span class="token punctuation">(</span>pool<span class="token punctuation">,</span> my_input<span class="token punctuation">,</span> mapper<span class="token punctuation">,</span> reducer<span class="token punctuation">,</span> chunk_size<span class="token punctuation">,</span> callback<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment" spellcheck="true">#XXX</span>
    map_returns <span class="token operator">=</span> chunked_async_map<span class="token punctuation">(</span>pool<span class="token punctuation">,</span> mapper<span class="token punctuation">,</span> my_input<span class="token punctuation">,</span> chunk_size<span class="token punctuation">)</span>
    report_progress<span class="token punctuation">(</span>map_returns<span class="token punctuation">,</span> <span class="token string">'map'</span><span class="token punctuation">,</span> callback<span class="token punctuation">)</span>
    map_results <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> ret <span class="token keyword">in</span> map_returns<span class="token punctuation">:</span>
        map_results<span class="token punctuation">.</span>extend<span class="token punctuation">(</span>ret<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true"># EXTEND</span>
    distributor <span class="token operator">=</span> defaultdict<span class="token punctuation">(</span>list<span class="token punctuation">)</span>
    <span class="token keyword">for</span> key<span class="token punctuation">,</span> value <span class="token keyword">in</span> map_results<span class="token punctuation">:</span>
        distributor<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>value<span class="token punctuation">)</span>
    returns <span class="token operator">=</span> chunked_async_map<span class="token punctuation">(</span>pool<span class="token punctuation">,</span> reducer<span class="token punctuation">,</span> distributor<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> chunk_size<span class="token punctuation">)</span>
    report_progress<span class="token punctuation">(</span>returns<span class="token punctuation">,</span> <span class="token string">'reduce'</span><span class="token punctuation">,</span> callback<span class="token punctuation">)</span>
    results <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> ret <span class="token keyword">in</span> returns<span class="token punctuation">:</span>
        results<span class="token punctuation">.</span>extend<span class="token punctuation">(</span>ret<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> results


<span class="token keyword">def</span> <span class="token function">reporter</span><span class="token punctuation">(</span>tag<span class="token punctuation">,</span> done<span class="token punctuation">,</span> not_done<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'Operation {tag}: {done}/{done+not_done}'</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>新增处理Ctrl+C的信号，使得服务优雅终止：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> asyncio
<span class="token keyword">from</span> functools <span class="token keyword">import</span> partial
<span class="token keyword">import</span> marshal
<span class="token keyword">import</span> multiprocessing <span class="token keyword">as</span> mp
<span class="token keyword">import</span> pickle
<span class="token keyword">from</span> queue <span class="token keyword">import</span> Empty<span class="token punctuation">,</span> Queue
<span class="token keyword">import</span> signal
<span class="token keyword">import</span> threading
<span class="token keyword">from</span> time <span class="token keyword">import</span> sleep <span class="token keyword">as</span> sync_sleep
<span class="token keyword">import</span> types

<span class="token keyword">import</span> chunk_mp_mapreduce <span class="token keyword">as</span> mr


<span class="token keyword">def</span> <span class="token function">handle_interrupt_signal</span><span class="token punctuation">(</span>server<span class="token punctuation">)</span><span class="token punctuation">:</span>
    server<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">while</span> server<span class="token punctuation">.</span>is_serving<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        sync_sleep<span class="token punctuation">(</span><span class="token number">0.1</span><span class="token punctuation">)</span>


work_queue <span class="token operator">=</span> Queue<span class="token punctuation">(</span><span class="token punctuation">)</span>
results_queue <span class="token operator">=</span> Queue<span class="token punctuation">(</span><span class="token punctuation">)</span>
results <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>


<span class="token keyword">async</span> <span class="token keyword">def</span> <span class="token function">submit_job</span><span class="token punctuation">(</span>job_id<span class="token punctuation">,</span> reader<span class="token punctuation">,</span> writer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    writer<span class="token punctuation">.</span>write<span class="token punctuation">(</span>job_id<span class="token punctuation">.</span>to_bytes<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token string">'little'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
    code_size <span class="token operator">=</span> int<span class="token punctuation">.</span>from_bytes<span class="token punctuation">(</span><span class="token keyword">await</span> reader<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'little'</span><span class="token punctuation">)</span>
    my_code <span class="token operator">=</span> marshal<span class="token punctuation">.</span>loads<span class="token punctuation">(</span><span class="token keyword">await</span> reader<span class="token punctuation">.</span>read<span class="token punctuation">(</span>code_size<span class="token punctuation">)</span><span class="token punctuation">)</span>
    data_size <span class="token operator">=</span> int<span class="token punctuation">.</span>from_bytes<span class="token punctuation">(</span><span class="token keyword">await</span> reader<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'little'</span><span class="token punctuation">)</span>
    data <span class="token operator">=</span> pickle<span class="token punctuation">.</span>loads<span class="token punctuation">(</span><span class="token keyword">await</span> reader<span class="token punctuation">.</span>read<span class="token punctuation">(</span>data_size<span class="token punctuation">)</span><span class="token punctuation">)</span>
    work_queue<span class="token punctuation">.</span>put_nowait<span class="token punctuation">(</span><span class="token punctuation">(</span>job_id<span class="token punctuation">,</span> my_code<span class="token punctuation">,</span> data<span class="token punctuation">)</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">get_results_queue</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">while</span> results_queue<span class="token punctuation">.</span>qsize<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span>
        <span class="token keyword">try</span><span class="token punctuation">:</span>
            job_id<span class="token punctuation">,</span> data <span class="token operator">=</span> results_queue<span class="token punctuation">.</span>get_nowait<span class="token punctuation">(</span><span class="token punctuation">)</span>
            results<span class="token punctuation">[</span>job_id<span class="token punctuation">]</span> <span class="token operator">=</span> data
        <span class="token keyword">except</span> Empty<span class="token punctuation">:</span>
            <span class="token keyword">return</span>


<span class="token keyword">async</span> <span class="token keyword">def</span> <span class="token function">get_results</span><span class="token punctuation">(</span>reader<span class="token punctuation">,</span> writer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    get_results_queue<span class="token punctuation">(</span><span class="token punctuation">)</span>
    job_id <span class="token operator">=</span> int<span class="token punctuation">.</span>from_bytes<span class="token punctuation">(</span><span class="token keyword">await</span> reader<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'little'</span><span class="token punctuation">)</span>
    data <span class="token operator">=</span> pickle<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>None<span class="token punctuation">)</span>
    <span class="token keyword">if</span> job_id <span class="token keyword">in</span> results<span class="token punctuation">:</span>
        data <span class="token operator">=</span> pickle<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>results<span class="token punctuation">[</span>job_id<span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">del</span> results<span class="token punctuation">[</span>job_id<span class="token punctuation">]</span>
    writer<span class="token punctuation">.</span>write<span class="token punctuation">(</span>len<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">.</span>to_bytes<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token string">'little'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    writer<span class="token punctuation">.</span>write<span class="token punctuation">(</span>data<span class="token punctuation">)</span>


<span class="token keyword">async</span> <span class="token keyword">def</span> <span class="token function">accept_requests</span><span class="token punctuation">(</span>reader<span class="token punctuation">,</span> writer<span class="token punctuation">,</span> job_id<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    op <span class="token operator">=</span> <span class="token keyword">await</span> reader<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> op<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        <span class="token keyword">await</span> submit_job<span class="token punctuation">(</span>job_id<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> reader<span class="token punctuation">,</span> writer<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># XXX Errors in async</span>
        job_id<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>
    <span class="token keyword">elif</span> op<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
        <span class="token keyword">await</span> get_results<span class="token punctuation">(</span>reader<span class="token punctuation">,</span> writer<span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">worker</span><span class="token punctuation">(</span>pool<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>
        job_id<span class="token punctuation">,</span> code<span class="token punctuation">,</span> data <span class="token operator">=</span> work_queue<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> job_id <span class="token operator">==</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>
            <span class="token keyword">break</span>
        func <span class="token operator">=</span> types<span class="token punctuation">.</span>FunctionType<span class="token punctuation">(</span>code<span class="token punctuation">,</span> globals<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'mapper_and_reducer'</span><span class="token punctuation">)</span>
        mapper<span class="token punctuation">,</span> reducer <span class="token operator">=</span> func<span class="token punctuation">(</span><span class="token punctuation">)</span>
        counts <span class="token operator">=</span> mr<span class="token punctuation">.</span>map_reduce<span class="token punctuation">(</span>pool<span class="token punctuation">,</span> data<span class="token punctuation">,</span> mapper<span class="token punctuation">,</span> reducer<span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> mr<span class="token punctuation">.</span>reporter<span class="token punctuation">)</span>
        results_queue<span class="token punctuation">.</span>put<span class="token punctuation">(</span><span class="token punctuation">(</span>job_id<span class="token punctuation">,</span> counts<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Worker thread terminating'</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">init_worker</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    signal<span class="token punctuation">.</span>signal<span class="token punctuation">(</span>signal<span class="token punctuation">.</span>SIGINT<span class="token punctuation">,</span> signal<span class="token punctuation">.</span>SIG_IGN<span class="token punctuation">)</span>


<span class="token keyword">async</span> <span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    server <span class="token operator">=</span> <span class="token keyword">await</span> asyncio<span class="token punctuation">.</span>start_server<span class="token punctuation">(</span>accept_requests<span class="token punctuation">,</span> <span class="token string">'127.0.0.1'</span><span class="token punctuation">,</span> <span class="token number">1936</span><span class="token punctuation">)</span>
    mp_pool <span class="token operator">=</span> mp<span class="token punctuation">.</span>Pool<span class="token punctuation">(</span>initializer<span class="token operator">=</span>init_worker<span class="token punctuation">)</span>
    loop <span class="token operator">=</span> asyncio<span class="token punctuation">.</span>get_running_loop<span class="token punctuation">(</span><span class="token punctuation">)</span>    
    loop<span class="token punctuation">.</span>add_signal_handler<span class="token punctuation">(</span>signal<span class="token punctuation">.</span>SIGINT<span class="token punctuation">,</span> partial<span class="token punctuation">(</span>handle_interrupt_signal<span class="token punctuation">,</span> server<span class="token operator">=</span>server<span class="token punctuation">)</span><span class="token punctuation">)</span>
    worker_thread <span class="token operator">=</span> threading<span class="token punctuation">.</span>Thread<span class="token punctuation">(</span>target<span class="token operator">=</span>partial<span class="token punctuation">(</span>worker<span class="token punctuation">,</span> pool<span class="token operator">=</span>mp_pool<span class="token punctuation">)</span><span class="token punctuation">)</span>
    worker_thread<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">async</span> <span class="token keyword">with</span> server<span class="token punctuation">:</span>
        <span class="token keyword">try</span><span class="token punctuation">:</span>
            <span class="token keyword">await</span> server<span class="token punctuation">.</span>serve_forever<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">except</span> asyncio<span class="token punctuation">.</span>exceptions<span class="token punctuation">.</span>CancelledError<span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Server cancelled'</span><span class="token punctuation">)</span>
    work_queue<span class="token punctuation">.</span>put<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    worker_thread<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">)</span>
    mp_pool<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
    mp_pool<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Bye Bye!'</span><span class="token punctuation">)</span>


asyncio<span class="token punctuation">.</span>run<span class="token punctuation">(</span>main<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>本章主要介绍了一个基于socket的简单版本的MapReduce框架，从单进程单线程演化为多进程多线程版本，最后还做了优雅停止的处理。</p>
<p>下一章主要介绍NumPy的高性能计算。</p>

</article>
    
    

</div>
<div class="trm-post-next-prev row">
    <div class="col-lg-12">
        <!-- title -->
        <h5 class="trm-title-with-divider">
            其他文章
            <span data-number="02"></span>
        </h5>
    </div>
    
        <div class="col-lg-6">
    <div class="trm-blog-card trm-scroll-animation">
        <a href="/2024/05/26/LeetCode-206-%E5%8F%8D%E8%BD%AC%E9%93%BE%E8%A1%A8/" class="trm-cover-frame trm-anima-link">
            
            
                <img alt="cover" class="no-fancybox" src="/img/block.jpg">
            
        </a>
        
        <div class="trm-card-descr">
            <div class="trm-label trm-category trm-mb-20">
                <a href=" #.">
                    未分类
                </a>
            </div>
            <h5>
                <a href="/2024/05/26/LeetCode-206-%E5%8F%8D%E8%BD%AC%E9%93%BE%E8%A1%A8/" class="trm-anima-link">
                    LeetCode-206-反转链表
                </a>
            </h5>
            <div class="trm-divider trm-mb-20 trm-mt-20"></div>
            <ul class="trm-card-data trm-label">
                <li>24/05/26</li>
                <li>13:36</li>
                
                
            </ul>
        </div>
    </div>
</div>
    
    
        <div class="col-lg-6">
    <div class="trm-blog-card trm-scroll-animation">
        <a href="/2024/05/24/Fast-Python%E7%AC%94%E8%AE%B0%E4%B8%80/" class="trm-cover-frame trm-anima-link">
            
            
                <img alt="cover" class="no-fancybox" src="/img/block.jpg">
            
        </a>
        
        <div class="trm-card-descr">
            <div class="trm-label trm-category trm-mb-20">
                <a href=" #.">
                    未分类
                </a>
            </div>
            <h5>
                <a href="/2024/05/24/Fast-Python%E7%AC%94%E8%AE%B0%E4%B8%80/" class="trm-anima-link">
                    Fast Python笔记一
                </a>
            </h5>
            <div class="trm-divider trm-mb-20 trm-mt-20"></div>
            <ul class="trm-card-data trm-label">
                <li>24/05/24</li>
                <li>19:50</li>
                
                
            </ul>
        </div>
    </div>
</div>
    
</div>

    



                    <div class="trm-divider footer-divider"></div>

                    <!-- footer -->
                    <footer class="trm-scroll-animation">

    

    

    
        <div class="trm-footer-item">
            <span>
                由 <a href="https://hexo.io" target="_blank" rel="noopener">Hexo</a> 驱动 v7.0.0
            </span>
            <span class="footer-separator" data-separator=" | "></span>
            <span> 
                主题 - 
                <a rel="noopener" href='https://github.com/MaLuns/hexo-theme-async' target='_blank'>Async</a>
                v2.1.8
            </span>
        </div>
      

     

     
</footer>
 
                    <!-- footer end -->

                </div>
            </div>
        </div>
    </div>
</div>
            <!-- body end -->

            

            
<div class="trm-fixed-container">
    
    
        <div class="trm-fixed-btn" data-title="阅读模式" onclick="asyncFun.switchReadMode()">
            <i class="iconfont fas fa-book-reader"></i>
        </div>
    
    
    <div id="trm-back-top" class="trm-fixed-btn" data-title="回到顶部">
        <i class="iconfont fas fa-arrow-up"></i>
    </div>
</div>
        </div>
      </div>
      <!-- scroll container end -->
  </div>
  <!-- app wrapper end -->

  
  <!-- Plugin -->




    
    
<script src="https://unpkg.com/@fancyapps/ui@4.0/dist/fancybox.umd.js"></script>

    

    

    

    <!-- 数学公式 -->
    

    <!-- 评论插件 -->
    
        

        
    



<!-- CDN -->


    

    

    




    <!-- Service Worker -->
    
    <!-- baidu push -->
    


<script id="async-script" src="/js/main.js?v=2.1.8"></script>

</body>

</html>